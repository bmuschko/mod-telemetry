input {
  http {
    port => 8080
    codec => plain
    response_code => 200
    additional_codecs => {
      "application/json" => "json"
    }
  }
}

filter {
  # Handle CSV data
  if [headers][content-type] =~ /text\/csv/ or [headers][content-type] =~ /text\/plain/ {
    csv {
      separator => ","
      columns => [
        "origin",
        "path",
        "branch",
        "developer",
        "buildSuccess",
        "buildStartTime",
        "buildEndTime",
        "buildId",
        "buildChangeset",
        "buildDependencyResolutionTimeMs",
        "buildMavenVersion",
        "buildGradleVersion",
        "buildBazelVersion",
        "buildDotnetVersion",
        "buildPythonVersion",
        "buildNodeVersion",
        "buildSourceFileCount",
        "buildLineCount",
        "buildParseErrorCount",
        "buildWeight",
        "buildMaxWeight",
        "buildMaxWeightSourceFile",
        "buildElapsedTimeMs",
        "cloneSuccess",
        "cloneCloneUri",
        "cloneStartTime",
        "cloneEndTime",
        "cloneChangeset",
        "cloneElapsedTimeMs",
        "organization"
      ]
      skip_header => true
      skip_empty_columns => true
    }

    # Convert data types
    mutate {
      convert => {
        "buildSuccess" => "boolean"
        "buildDependencyResolutionTimeMs" => "integer"
        "buildSourceFileCount" => "integer"
        "buildLineCount" => "integer"
        "buildParseErrorCount" => "integer"
        "buildWeight" => "float"
        "buildMaxWeight" => "float"
        "buildElapsedTimeMs" => "integer"
        "cloneSuccess" => "boolean"
        "cloneElapsedTimeMs" => "integer"
      }
    }

    # Parse timestamps
    date {
      match => [ "buildStartTime", "ISO8601", "yyyy-MM-dd HH:mm:ss", "yyyy-MM-dd'T'HH:mm:ss.SSSZ" ]
      target => "buildStartTimeParsed"
    }

    date {
      match => [ "buildEndTime", "ISO8601", "yyyy-MM-dd HH:mm:ss", "yyyy-MM-dd'T'HH:mm:ss.SSSZ" ]
      target => "buildEndTimeParsed"
    }

    date {
      match => [ "cloneStartTime", "ISO8601", "yyyy-MM-dd HH:mm:ss", "yyyy-MM-dd'T'HH:mm:ss.SSSZ" ]
      target => "cloneStartTimeParsed"
    }

    date {
      match => [ "cloneEndTime", "ISO8601", "yyyy-MM-dd HH:mm:ss", "yyyy-MM-dd'T'HH:mm:ss.SSSZ" ]
      target => "cloneEndTimeParsed"
    }

    # Calculate additional metrics
    ruby {
      code => '
        # Calculate build duration if times are available
        if event.get("buildStartTimeParsed") && event.get("buildEndTimeParsed")
          duration = event.get("buildEndTimeParsed").to_f - event.get("buildStartTimeParsed").to_f
          event.set("buildDurationSeconds", duration)
        end

        # Calculate clone duration if times are available
        if event.get("cloneStartTimeParsed") && event.get("cloneEndTimeParsed")
          duration = event.get("cloneEndTimeParsed").to_f - event.get("cloneStartTimeParsed").to_f
          event.set("cloneDurationSeconds", duration)
        end

        # Determine build tool
        build_tools = []
        build_tools << "Maven" if event.get("buildMavenVersion")
        build_tools << "Gradle" if event.get("buildGradleVersion")
        build_tools << "Bazel" if event.get("buildBazelVersion")
        build_tools << "Dotnet" if event.get("buildDotnetVersion")
        build_tools << "Python" if event.get("buildPythonVersion")
        build_tools << "Node" if event.get("buildNodeVersion")
        event.set("buildTools", build_tools) unless build_tools.empty?

        # Set build status
        if event.get("buildSuccess") == true
          event.set("buildStatus", "success")
        elsif event.get("buildSuccess") == false
          event.set("buildStatus", "failed")
        else
          event.set("buildStatus", "unknown")
        end
      '
    }

    # Add metadata
    mutate {
      add_field => {
        "processed_at" => "%{@timestamp}"
        "data_type" => "build_metrics"
      }

      # Clean up temporary parsed fields
      remove_field => ["headers", "host", "@version"]
    }
  }

  # Handle JSON payload with CSV data
  if [headers][content-type] =~ /application\/json/ {
    if [csv_data] {
      mutate {
        split => { "csv_data" => "\n" }
      }

      split {
        field => "csv_data"
      }

      csv {
        source => "csv_data"
        separator => ","
        columns => [
          "origin", "path", "branch", "developer", "buildSuccess",
          "buildStartTime", "buildEndTime", "buildId", "buildChangeset",
          "buildDependencyResolutionTimeMs", "buildMavenVersion", "buildGradleVersion",
          "buildBazelVersion", "buildDotnetVersion", "buildPythonVersion", "buildNodeVersion",
          "buildSourceFileCount", "buildLineCount", "buildParseErrorCount",
          "buildWeight", "buildMaxWeight", "buildMaxWeightSourceFile", "buildElapsedTimeMs",
          "cloneSuccess", "cloneCloneUri", "cloneStartTime", "cloneEndTime",
          "cloneChangeset", "cloneElapsedTimeMs", "organization"
        ]
        skip_header => false
      }

      mutate {
        remove_field => ["csv_data"]
      }
    }
  }

  # Data validation
  if ![buildId] or ![developer] {
    mutate {
      add_tag => ["validation_error", "missing_required_fields"]
    }
  }

  if [buildParseErrorCount] and [buildParseErrorCount] > 0 {
    mutate {
      add_tag => ["has_parse_errors"]
    }
  }

  if [buildElapsedTimeMs] and [buildElapsedTimeMs] > 600000 {  # 10 minutes
    mutate {
      add_tag => ["slow_build"]
    }
  }
}

output {
  # Console output for debugging
  stdout {
    codec => rubydebug
  }

  # Store in Elasticsearch with proper index
  elasticsearch {
    hosts => ["localhost:9200"]
    index => "build-metrics-%{+YYYY.MM.dd}"
    document_id => "%{buildId}-%{[@timestamp]}"
  }

  # Send to monitoring API
  # http {
  #   url => "http://localhost:3000/api/build-metrics"
  #   http_method => "post"
  #   format => "json"
  # }
}